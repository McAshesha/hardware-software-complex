{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a094d9-2b91-47ce-ad35-bd6fa61a15e5",
   "metadata": {},
   "source": [
    "# Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03681-2772-4b40-acb0-d531b76dc9ef",
   "metadata": {},
   "source": [
    "# Модель нейронной сети\n",
    "### Синапс нейронной сети\n",
    "<img src=\"images/LessonsII/synaps.png\" alt=\"Synaps\" height=30% width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c9381-83c9-4a0f-a7a3-30db9fcfbda4",
   "metadata": {},
   "source": [
    "# Полносвязная неронная сеть\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/1200px-Neural_network.svg.png\" alt=\"FCNeuralNetwork\" width=30% height=30%>\n",
    "Схема простой нейросети. Зелёным цветом обозначены входные нейроны, голубым — скрытые нейроны, жёлтым — выходной нейрон\n",
    "\n",
    "$$\n",
    "\\vec {h_t} = W_h \\vec x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec h = F_h(\\vec{h_t})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec {y_t} = W_y \\vec h\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec y = F_y(\\vec{y_t})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9fc9c-0c4c-4cad-ac77-04da45727ac2",
   "metadata": {},
   "source": [
    "# Полносвязная нейронная сеть\n",
    "\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/10/obuchenie-neironnyh-setei-glubokoe.gif\" alt=\"FCNeuralNetwork\" width=60% height=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d9355-a735-4370-a3e6-8ebc85a3a5fc",
   "metadata": {},
   "source": [
    "https://adamharley.com/nn_vis/mlp/2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5f3e8-7dda-4dcd-97c4-22febeb44b26",
   "metadata": {},
   "source": [
    "# Функция активации\n",
    "## Сигмоида\n",
    "<img src=\"images/LessonsII/sigmoid.png\" width=30% height=30% />\n",
    "$$\n",
    "F(x) = {1 \\over 1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65e9ba-9f3d-4170-b597-150469627efd",
   "metadata": {},
   "source": [
    "## Гиперболический тангенс\n",
    "<img src=\"images/LessonsII/tanh.png\" width=30% height=30% />\n",
    "\n",
    "$$\n",
    "F(x) = {e^{2x}-1 \\over e^{2x}+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc1e4-9f35-4763-9d95-0c5f078a3792",
   "metadata": {},
   "source": [
    "## ReLU (rectified linear unit)\n",
    "<img src=\"images/LessonsII/ReLU.png\" width=40% height=40% />\n",
    "$$\n",
    "F(x) = max(0, x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cffddb-a964-4573-83b4-5bae0d2a2082",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "Применяется в тех случаях, когда необходимо, чтобы сумма элементов была равно 1, а каждый элемент принадлежал интервалу \\[0; 1\\] (для задач классификации)\n",
    "$$\n",
    "F(x) = {e^{x} \\over \\sum_j e^{x_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a7f2c-9ba2-4684-9e5f-9518b8e912d5",
   "metadata": {},
   "source": [
    "# Метод Обратного Распространения\n",
    "#### https://habr.com/ru/articles/313216/\n",
    "\n",
    "<img src=\"https://habrastorage.org/files/dad/168/f54/dad168f54a2d4cf0b6508200eda50eef.png\" alt=\"Example\" height=30% width=30%>\n",
    "Ошибка выходного нейрона\n",
    "$$\n",
    "\\delta_{output} = (out_{pred} - out_{y})f'(in)\n",
    "$$\n",
    "Ошибка внутренного нейрона\n",
    "$$\n",
    "\\delta_{hid} = f'(in)\\sum_i(w_i\\delta_i)\n",
    "$$\n",
    "Градиент ошибки нейрона\n",
    "$$\n",
    "grad_a^b = out_a*\\delta_b\n",
    "$$\n",
    "Изменение весов\n",
    "$$\n",
    "\\Delta w_t = E*grad_a^b+\\alpha*\\Delta w_{t-1}\n",
    "$$\n",
    "\n",
    "*E* - скорость обучения  \n",
    "$\\alpha$ - момент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1731cd0-a80c-433a-9544-bffbaff1f946",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"images/LessonsII/backprop.gif\" width=70% height=70% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3540cef-533d-4c93-8be4-1565f236a8f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ошибка выходного нейрона\n",
    "$$\n",
    "\\delta_{6} = (out_{pred} - out_{y})f'(in)\n",
    "$$\n",
    "\n",
    "Производная от функции активации\n",
    "$$\n",
    "\\sigma(in)' = \\sigma(in) * (1 - \\sigma(in))\n",
    "$$\n",
    "\n",
    "Ошибка внутренного нейрона No5 ($\\delta_{5}$)\n",
    "$$\n",
    "\\delta_{5} = \\sigma(in)' * w_{56} * \\delta_{6} = \\sigma(in)(1 - \\sigma(in)) * w_{56} * \\delta_{6} = out_{y} (1 - out_{y}) * w_{56} * \\delta_{6}\n",
    "$$\n",
    "\n",
    "Градиент ошибки нейрона No5 \n",
    "$$\n",
    "grad_6^5 = \\delta_{5} * f_{5}(in)\n",
    "$$\n",
    "\n",
    "Изменение весов\n",
    "$$\n",
    "w_{56} = w_{56} - \\lambda *grad_5^6\n",
    "$$\n",
    "\n",
    "$\\lambda$ - скорость обучения  \n",
    "$\\alpha$ - момент\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb71594-5b42-428c-9a2a-15d55f9b1808",
   "metadata": {},
   "source": [
    "<img src=\"images/LessonsII/common_act_func.png\" width=70% height=70% />\n",
    " Скорость обучения logistic-ой функции активации низкая с определенного момента (x > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43c6d2-a4c5-46aa-ac77-6ff2bd37cfbb",
   "metadata": {},
   "source": [
    "### Значение момента\n",
    "![Momentum](https://habrastorage.org/files/4d9/684/061/4d96840618dc44768e57e892033a119a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0267b1-6de3-4ef4-b057-b129fb4e58d5",
   "metadata": {},
   "source": [
    "# Функция потерь\n",
    "### Регрессия\n",
    "**Средняя абсолютная ошибка**\n",
    "$$\n",
    "MAE = {1\\over n}\\sum_{i=1}^n|y_i - pred_i|\n",
    "$$\n",
    "*n - число признаков в выходном векторе*  \n",
    "*pred - предсказанный вектор*\n",
    "  \n",
    "**Средняя квадратичная ошибка**\n",
    "$$\n",
    "MSE = {1\\over n}\\sum_{i=1}^n(y_i - pred_i)^2\n",
    "$$\n",
    "**Средняя абсолютная процентная ошибка**\n",
    "$$\n",
    "MAPE = {100\\% \\over n}\\sum_{i=1}^n{|y_i - pred_i|\\over y_i}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958f88f6-0c6a-478e-9ca1-7983b26fb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28814f28-de88-47a4-8d38-b4a8d2bc0e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20000000000000004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE\n",
    "def mean_absolute_error(y, pred):\n",
    "    diff = y - pred # находим разницу между  наблюдаемыми значениями (y) и прогнозируемыми (pred)\n",
    "    abs_diff = np.absolute(diff) # находим абсолютную разность между прогнозами и фактическими наблюдениями.\n",
    "    mean_diff = abs_diff.mean() # находим среднее значение\n",
    "    return mean_diff\n",
    "\n",
    "y = np.array([1.1,2,1.7]) # создаем список актуальных значений\n",
    "pred = np.array([1,1.7,1.5]) # список прогнозируемых значений\n",
    "\n",
    "# mean_absolute_error(y, pred) # sklearn\n",
    "mean_absolute_error(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545f84b5-7cc0-46b6-b16c-72784c554b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "def mean_squared_error(y, pred):\n",
    "    diff = y - pred # находим разницу между  наблюдаемыми значениями (y) и прогнозируемыми (pred)\n",
    "    differences_squared = diff ** 2 # возводим в квадрат (чтобы избавиться от отрицательных значений)\n",
    "    mean_diff = differences_squared.mean() # находим среднее значение\n",
    "\n",
    "    return mean_diff\n",
    "\n",
    "y = np.array([1.1,2,1.7]) \n",
    "pred = np.array([1,1.7,1.5]) \n",
    "\n",
    "# mean_squared_error(y, pred) # sklearn\n",
    "mean_squared_error(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bb67c6-df53-4e26-96ed-9c7d55a76809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21602468994692867"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "def root_mean_squared_error(y, pred):\n",
    "    diff = y - pred # находим разницу между  наблюдаемыми значениями (y) и прогнозируемыми (pred)\n",
    "    differences_squared = diff ** 2 # возводим в квадрат\n",
    "    mean_diff = differences_squared.mean() # находим среднее значение\n",
    "    rmse_val = np.sqrt(mean_diff) # извлекаем квадратный корень\n",
    "    return rmse_val\n",
    "\n",
    "y = np.array([1.1,2,1.7])\n",
    "pred = np.array([1,1.7,1.5])\n",
    "\n",
    "# mean_squared_error(y, pred, squared = False) #Если установлено значение False, функция возвращает значение RMSE.\n",
    "root_mean_squared_error(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8929d42-ceac-4707-9b02-5670f171a82a",
   "metadata": {},
   "source": [
    "### Классификация\n",
    "**Бинарная кросс энтропия**\n",
    "$$\n",
    "CE = -y_1log(pred_1)-(1-y_1)log(1-pred_1)\n",
    "$$\n",
    "**Категориальная кросс энтропия**\n",
    "$$\n",
    "CE = -\\sum_j^Cy_jlog(pred_j)\n",
    "$$\n",
    "*C - число классов*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ab3c6d-c537-4c8f-9e94-1d6b3cee6359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21616187468057912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_cross_entropy(y, pred):\n",
    "    y = np.array([1 if el == \"Cat\" else 0 for el in y]) # [[0 1 1 0]]\n",
    "    pred = np.array([el[0] for el in pred])\n",
    "    CE = -y*np.log(pred) - (1 - y)*np.log((1-pred))\n",
    "    return CE.mean()\n",
    "\n",
    "labels = {\"Cat\": [1, 0], \"Dog\":[0,1]}\n",
    "\n",
    "def encode_label(y):\n",
    "    return np.array([labels[key] for key in y])\n",
    "\n",
    "def cross_entropy(y, pred):\n",
    "    y = encode_label(y) # [[0, 1], [1, 0], [1, 0], [0, 1]]\n",
    "    pred = np.array(pred)\n",
    "    CE = -np.sum(y*np.log(pred), axis=-1)\n",
    "    return CE.mean()\n",
    "\n",
    "y = [\"Dog\", \"Cat\", \"Cat\", \"Dog\"] # список правильных меток классов\n",
    "pred = [[.1, .9], [.9, .1], [.8, .2], [.35, .65]] # [P(dog), P(cat)] # список вероятностей, предсказанных моделью.\n",
    "\n",
    "# (Первый аргумент в вызове функции — это список правильных меток классов для каждого входа. Второй аргумент — это список вероятностей, предсказанных моделью.)\n",
    "# log_loss(y, pred) # sklearn \n",
    "cross_entropy(y, pred) # binary_cross_entropy(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c964808d-0470-4518-bf4d-73e3adef2693",
   "metadata": {},
   "source": [
    "<img src=\"images/LessonsII/cross_entr.png\" alt=\"SoftMax\" height=80% width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790fe07-c1ef-4921-a6ab-355d2532816d",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети\n",
    "\n",
    "![Архитектура](https://upload.wikimedia.org/wikipedia/commons/5/55/%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D0%B9_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde2776-e2cb-4e22-8ecb-cf5762443bd5",
   "metadata": {},
   "source": [
    "Слой свёртки (convolutional layer) — это основной блок свёрточной нейронной сети. Слой свёртки включает в себя для каждого канала свой фильтр, ядро свёртки которого обрабатывает предыдущий слой по фрагментам (суммируя результаты поэлементного произведения для каждого фрагмента). Весовые коэффициенты ядра свёртки (небольшой матрицы) неизвестны и устанавливаются в процессе обучения.\n",
    "\n",
    "![Свёртка](https://neurohive.io/wp-content/uploads/2018/07/2d-covolutions.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5138e-f2d2-4fa3-b6a3-51fcb1112188",
   "metadata": {},
   "source": [
    "### Свёртка\n",
    "<img src=\"images/LessonsII/convolution.jpeg\" alt=\"Conv\" height=40% width=40%>\n",
    "$$O_{i, j} = f(K*I_{i-s:i+s, j-s:j+s})$$\n",
    "\n",
    "$K$ - ядро свёртки  \n",
    "$I$ - входной тезнор  \n",
    "$I_{i-s:i+s, j-s:j+s}$ - срез тензора размера ядра свёртки с центром в точке (i, j)  \n",
    "$O_{i, j}$ - результат свёртки (значение выходного тензора в точке (i, j))  \n",
    "$f$ - функция активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d3761-18a9-4ff1-bb0c-9fa89d1ea6b2",
   "metadata": {},
   "source": [
    "# Граф вычислений\n",
    "<img src=\"images/LessonsII/graph.png\" alt=\"gr\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013da17-f469-4726-a2fa-b9dd9e28be2c",
   "metadata": {},
   "source": [
    "# Обратное распространение ошибки. Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d239481-051f-4d3d-a566-7e35284c2bf3",
   "metadata": {},
   "source": [
    "- функция:\n",
    "$$f(x,w) = 1 + e^{w_1x+w_0}$$\n",
    "<img src=\"images/LessonsII/back1_1.png\" alt=\"Back1\" height=40% width=40%>\n",
    "\n",
    "- Начальное состояение весов и входного значения:\n",
    "<img src=\"images/LessonsII/back1_2.png\" alt=\"back1_2\" height=40% width=40%>\n",
    "\n",
    "- Посчитаем значения по прямому проходу\n",
    "<img src=\"images/LessonsII/back1_3.png\" height=40% width=40%>\n",
    "\n",
    "- Для удобства обозначим узлы (подфункции)\n",
    "<img src=\"images/LessonsII/back1_4.png\" alt=\"back1_4\" height=40% width=40%>\n",
    "\n",
    "- Обратное распространение. Пусть df = 1. Тогда \n",
    "$$dc = {df \\over dc}df = (c+1)'_{c} * 1 = 1$$\n",
    "$$db = {dc \\over db}dc = (e^b)'_{b} * 1 = e^3 = 20$$\n",
    "<img src=\"images/LessonsII/back1_5.png\" height=40% width=40%>\n",
    "\n",
    "$$dw_0 = {db \\over dw_0}db = (a+w_0)'_{w_0} * 20 = 20$$\n",
    "$$da = {db \\over da}db = (a+w_0)'_{a} * 20 = 20$$\n",
    "<img src=\"images/LessonsII/back1_6.png\" height=40% width=40%>\n",
    "\n",
    "$$dw_1 = {da \\over dw_1}da = (x*w_1)'_{w_1} * 20 = x*20 = 20$$\n",
    "$$dx = {da \\over dx}da = (x*w_1)'_{x} * 20 = w_1*20 = 40$$\n",
    "<img src=\"images/LessonsII/back1_7.png\" height=40% width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434172f-1945-4405-9e7c-f03ec4fd77fe",
   "metadata": {},
   "source": [
    "# Обратное распространение ошибки. Пример с матрицами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de85d8-66a9-4e93-b1be-b223ebb251ac",
   "metadata": {},
   "source": [
    "$$f={1 \\over 2} ||X*W||^2_2$$\n",
    "<img src=\"images/LessonsII/back2_1.png\" height=40% width=40%>\n",
    "\n",
    "- Начальное состояение весов и входного значения\n",
    "<img src=\"images/LessonsII/back2_2.png\" height=40% width=40%>\n",
    "\n",
    "- Посчитаем значения по прямому проходу\n",
    "<img src=\"images/LessonsII/back2_3.png\" height=40% width=40%>\n",
    "\n",
    "- Для удобства обозначим узлы (подфункции)  \n",
    "<img src=\"images/LessonsII/back2_4.png\" height=40% width=40%>\n",
    "\n",
    "- Обратное распространение. Пусть df = 1. Тогда \n",
    "$$db = {df \\over db}df = ({1 \\over 2}b)'_{b} * 1 = 0.5$$\n",
    "$$da_{ij} = {db \\over da_{ij}}db = (a_{ij}^2)'_{a_{ij}} * 0.5 = a_{ij} $$\n",
    "или $$\\nabla_a f = a$$\n",
    "<img src=\"images/LessonsII/back2_5.png\" height=40% width=40%>\n",
    "\n",
    "$$\\nabla_w f = X^T \\nabla_a f$$\n",
    "\n",
    "<img src=\"images/LessonsII/back2_6.png\" height=40% width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523577d-090d-4ff8-a54a-185adcc6d7fc",
   "metadata": {},
   "source": [
    "# Переобучение\n",
    "**Недообучение** — нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.\n",
    "\n",
    "**Переобучение** (overtraining, overfitting) — нежелательное явление, возникающее при решении задач обучения по прецедентам, когда вероятность ошибки обученного алгоритма на объектах тестовой выборки оказывается существенно выше, чем средняя ошибка на обучающей выборке. Переобучение возникает при использовании избыточно сложных моделей.\n",
    "img src=\"images/LessonsII/Overfitting.svg.png\" width=80% height=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2725a7a-7415-4f55-ad35-732d5b262e7a",
   "metadata": {},
   "source": [
    "### Процесс обучения\n",
    "<img src=\"images/LessonsII/Overfitting.curve.png\" width=30% height=30% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68158d0-7b85-47c5-a8e2-1de41feb2a29",
   "metadata": {},
   "source": [
    "### Возможные решения при переобучении:\n",
    "* Увеличение количества данных в наборе;\n",
    "* Уменьшение количества параметров модели (количество параметров модели (весов) была в 2 - 3 раза меньше числа примеров обучающего множества);\n",
    "* Добавление регуляризации / увеличение коэффициента регуляризации.\n",
    "\n",
    "### Возможные решения при недообучении:\n",
    "* Добавление новых параметров модели;\n",
    "* Использование для описания модели функций с более высокой степенью;\n",
    "* Уменьшение коэффициента регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf598e-04d7-4e29-a68c-e64d0984fcba",
   "metadata": {},
   "source": [
    "# Аугментация данных\n",
    "\n",
    "**Аугментация данных** (data augmentation) – это методика создания дополнительных обучающих данных из имеющихся данных. Для достижения хороших результатов глубокие сети должны обучаться на очень большом объеме данных. Следовательно, если исходный обучающий набор содержит ограниченное количество изображений, необходимо выполнить аугментацию, чтобы улучшить результаты модели.\n",
    "\n",
    "Можно использовать следующие искажения:\n",
    "* Геометрические (афинные, проективные, ...);\n",
    "* Яркостные/цветовые;\n",
    "* Замена фона;\n",
    "* Искажения, характерные для решаемой задачи: блики, шумы, размытие и т. д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62648783-ab0d-48ec-91d5-be2662fe6aef",
   "metadata": {},
   "source": [
    "# Обучение с подкреплением\n",
    "Обучение с подкреплением — это метод машинного обучения, при котором происходит обучение модели, которая не имеет сведений о системе, но имеет возможность производить какие-либо действия в ней. Действия переводят систему в новое состояние и модель получает от системы некоторое вознаграждение\n",
    "\n",
    "<img src=\"images/LessonsII/reinforcement-learning-fig1-700.jpg\" alt=\"RF\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1aec9-c156-4183-872b-ee8d4616e633",
   "metadata": {},
   "source": [
    "## Обучение модели\n",
    "https://media.giphy.com/media/PH67wPdphHPk4/giphy.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11aedb2-b139-419d-abcf-cb8433707f66",
   "metadata": {},
   "source": [
    "# Ресурсы для углублённого изучения темы\n",
    "* Видеолекции Семёна Козлова - (https://www.youtube.com/channel/UCQj_dwbIydi588xrfjWSL5g/featured)\n",
    "* Курс по машинному обучению - (https://www.coursera.org/learn/machine-learning)\n",
    "* Цикл статей об истории нейронных сетей - (http://www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84311c-2502-42dc-9f11-9e17170356eb",
   "metadata": {},
   "source": [
    "# Задания\n",
    "\n",
    "См. Lesson 10.1\n",
    "\n",
    "# Лабораторная работа 10. Матчасть DL\n",
    "Задача: реализовать и обучить нейронную сеть, состоящую из 3 нейронов (2 слоя), предсказывать значения функции XOR. При выполнении лабораторной запрещается использовать фреймворки для глубокого обучения (как PyTorch, Tensorflow, Caffe, Theano и им подобные).\n",
    "\n",
    "В первую очередь ознакомиться с этим материалом (https://towardsdatascience.com/implementing-the-xor-gate-using-backpropagation-in-neural-networks-c1f255b4f20d).\n",
    "\n",
    "Что необходимо реализовать, используя знания и фрагменты кода из ссылки выше:  \n",
    "1. Класс Neuron, имеющий вектор весов self._weigths\n",
    "2. Два метода класса Neuron: forward(x), backward(x, loss) - реализующих прямой и обратный проход по нейронной сети. \n",
    "   Метод forward должен реализовывать логику работу нейрона: умножение входа на вес self._weigths, сложение и функцию активации сигмоиду. \n",
    "   Метод backward должен реализовывать взятие производной от сигмоиды и используя состояние нейрона обновить его веса.\n",
    "3. Реализовать с помощью класса Neuron нейронную сеть с архитектурой из трёх нейронов, предложенную в статье:\n",
    "<img src=\"images/LessonsII/Neuron.png\" alt=\"Neuron\" height=40% width=40%>\n",
    "\n",
    "\n",
    "4. Для красоты обернуть в класс Model с методами forward и backward, реализующими правильное взаимодействие нейронов на прямом и обратном проходах.\n",
    "5. Реализовать тренировочный цикл следующего вида:\n",
    "\n",
    "```  python\n",
    "цикл (обучающие данные):\n",
    "\ty = model.forward(x)\n",
    "\terr = loss(y, label)\n",
    "\tmodel.backward(x, err)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2786286e-0d3a-4196-b930-21beb506e1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0, (0, 1): 1, (1, 0): 1, (1, 1): 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В итоге обучения должны предсказываться значения аналогичные описанным в статье.  \n",
    "{(0,0):0, (0,1):1, (1, 0):1, (1,1):0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea9ebc-5d8c-4033-b166-3ba9b5897e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
