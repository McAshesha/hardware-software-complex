{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annual-sherman",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Библиотека torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd21945c-7ef0-442c-b572-7bb36c1b1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# см. pytorch_basics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854e84d",
   "metadata": {},
   "source": [
    "<img src=\"images/torch.png\" width=60% height=60%>\n",
    "TensorFlow проиграла (кроме TensorFlow lite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19989c4",
   "metadata": {},
   "source": [
    "## PyTorch — ваш новый фреймворк глубокого обучения\n",
    "https://habr.com/ru/post/334380/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5136f",
   "metadata": {},
   "source": [
    "Несколько фактов о PyTorch:\n",
    "- динамический граф вычислений\n",
    "- удобные модули `torch.nn` и `torchvision` для быстрого прототипирования нейронных сетей\n",
    "- даже быстрее, чем TensorFlow на некоторых задачах\n",
    "- позволяет легко использовать **GPU**\n",
    "\n",
    "Если бы PyTorch был формулой, она была бы такой:\n",
    "\n",
    "$$PyTorch = NumPy + CUDA + Autograd$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-fiction",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Установка\n",
    "```bash\n",
    "pip install torch\n",
    "```\n",
    "или https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-remark",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Математика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "embedded-luxembourg",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab88e79",
   "metadata": {},
   "source": [
    "### Типы Тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9645ec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.ByteTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.HalfTensor      # 16 бит, floating point\n",
    "torch.FloatTensor     # 32 бита, floating point\n",
    "torch.DoubleTensor    # 64 бита, floating point\n",
    "\n",
    "torch.ShortTensor     # 16 бит, integer, signed\n",
    "torch.IntTensor       # 32 бита, integer, signed\n",
    "torch.LongTensor      # 64 бита, integer, signed\n",
    "\n",
    "torch.CharTensor      # 8 бит, integer, signed\n",
    "torch.ByteTensor      # 8 бит, integer, unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e4729",
   "metadata": {},
   "source": [
    "### Создание тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rotary-promise",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 3.0000, 5.0000, 2.0000, 1.3000])\n",
      "tensor([-3.1416, -2.8109, -2.4802, -2.1495, -1.8188, -1.4881, -1.1574, -0.8267,\n",
      "        -0.4960, -0.1653,  0.1653,  0.4960,  0.8267,  1.1574,  1.4881,  1.8188,\n",
      "         2.1495,  2.4802,  2.8109,  3.1416])\n",
      "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,\n",
      "        4.5000, 5.0000, 5.5000, 6.0000, 6.5000, 7.0000, 7.5000, 8.0000, 8.5000,\n",
      "        9.0000, 9.5000])\n",
      "tensor([[[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 3, 5, 2, 1.3])\n",
    "print(x)\n",
    "x = torch.linspace(-np.pi, np.pi, 20, dtype=torch.float32)\n",
    "print(x)\n",
    "x = torch.arange(0, 10, 0.5, dtype=torch.float32)\n",
    "print(x)\n",
    "x = torch.ones(2, 1, 3, dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6c06671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0453e-05,  4.5687e-41, -1.3858e+13,  3.0868e-41],\n",
      "         [ 4.4842e-44,  0.0000e+00,  8.9683e-44,  0.0000e+00],\n",
      "         [-1.6435e+13,  3.0868e-41,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 9.1835e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  9.1084e-44,  0.0000e+00]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2,3,4) # размер тензора\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976ee0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10724207 0.55181834 0.5096208 ]\n",
      " [0.71071211 0.0153068  0.48715258]\n",
      " [0.38828255 0.69704577 0.48794508]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1072, 0.5518, 0.5096],\n",
       "        [0.7107, 0.0153, 0.4872],\n",
       "        [0.3883, 0.6970, 0.4879]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From NumPy\n",
    "a = np.random.rand(3, 3)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee642c64",
   "metadata": {},
   "source": [
    "### Инициализация тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97892e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((2,3))                # Normal(0, 1) с размером (2, 3)\n",
    "\n",
    "x.random_(0, 10)                      # Дискретное равномерно U[0, 10]\n",
    "x.uniform_(0, 1)                      # Равномерно U[0, 1]\n",
    "x.normal_(mean=0, std=1)              # Нормальное со средним 0 и дисперсией 1\n",
    "x.bernoulli_(p=0.5)                   # bernoulli with parameter p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22486f",
   "metadata": {},
   "source": [
    "### Операции над тензорами "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db9db5",
   "metadata": {},
   "source": [
    "### Изменение формы\n",
    "`np.reshape()` == `torch.view()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdd6657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "b = torch.FloatTensor([[1,2,3], [4,5,6]])\n",
    "print(b.shape)\n",
    "print(b.view(3, 2).shape)\n",
    "\n",
    "b = b[None, :,  :]\n",
    "#Тензор b можно развернуть в одномерный массив с помощью функции torch.view(-1), чтобы результат был вектором"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69922557",
   "metadata": {},
   "source": [
    "**Примечание:** `torch.view ()` создает новый тензор, но старый остается неизменным"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7e842",
   "metadata": {},
   "source": [
    "### Изменение типа тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde7d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  3, -7], dtype=torch.int32)\n",
      "tensor([ 1,  3, -7], dtype=torch.int32)\n",
      "tensor([  1,   3, 249], dtype=torch.uint8)\n",
      "tensor([  1,   3, 249], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([1.5, 3.2, -7])\n",
    "print(a.type_as(torch.IntTensor()) )\n",
    "print(a.to(torch.int32))\n",
    "\n",
    "print(a.type_as(torch.ByteTensor()))\n",
    "print(a.to(torch.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a9318",
   "metadata": {},
   "source": [
    "**Примечание:** `.type_as()` создает новый тензор, но старый остается неизменным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0061c102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5000,  3.2000, -7.0000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae76182",
   "metadata": {},
   "source": [
    "### Арифметические операции\n",
    "\n",
    "| операция | аналоги |\n",
    "|:-:|:-:|\n",
    "|`+`| `torch.add()` |\n",
    "|`-`| `torch.sub()` |\n",
    "|`*`| `torch.mul()` |\n",
    "|`/`| `torch.div()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b1a4982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [200., 400., 600.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
    "b = torch.Tensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bf7e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [200., 400., 600.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed64c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [200., 400., 600.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b += a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "309b0192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1.,    2.,    3.],\n",
      "        [  10.,   20.,   30.],\n",
      "        [-100., -200., -300.]])\n",
      "tensor([[   1.,    2.,    3.],\n",
      "        [  10.,   20.,   30.],\n",
      "        [-100., -200., -300.]])\n",
      "\n",
      "Поэлементное умножение\n",
      "tensor([[     0.,      0.,      0.],\n",
      "        [     0.,      0.,      0.],\n",
      "        [ 20000.,  80000., 180000.]])\n",
      "tensor([[     0.,      0.,      0.],\n",
      "        [     0.,      0.,      0.],\n",
      "        [ 20000.,  80000., 180000.]])\n",
      "\n",
      "Матричное умножение\n",
      "tensor([[   600.,   1200.,   1800.],\n",
      "        [  6000.,  12000.,  18000.],\n",
      "        [ 60000., 120000., 180000.]])\n",
      "tensor([[   600.,   1200.,   1800.],\n",
      "        [  6000.,  12000.,  18000.],\n",
      "        [ 60000., 120000., 180000.]])\n",
      "\n",
      " Деление\n",
      "tensor([[   inf,    inf,    inf],\n",
      "        [   inf,    inf,    inf],\n",
      "        [0.5000, 0.5000, 0.5000]])\n",
      "tensor([[   inf,    inf,    inf],\n",
      "        [   inf,    inf,    inf],\n",
      "        [0.5000, 0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(a - b)\n",
    "print(a.sub(b) )\n",
    "print('\\nПоэлементное умножение')\n",
    "print(a * b)\n",
    "print(a.mul(b))\n",
    "print('\\nМатричное умножение')\n",
    "print(a @ b) # Матричное умножение !!!\n",
    "print(a.mm(b))\n",
    "print('\\n Деление')\n",
    "print(a / b) # Поэлементное деление\n",
    "print(a.div(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25bb5f",
   "metadata": {},
   "source": [
    "**Примечание:** все эти операции создают новые тензоры, старые тензоры остаются неизменными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ad28d",
   "metadata": {},
   "source": [
    "### Операторы сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c17d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
    "b = torch.Tensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])\n",
    "a == b\n",
    "# a != b\n",
    "# a < b\n",
    "# a > b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d544e",
   "metadata": {},
   "source": [
    "### Использование индексации по логической маске"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa30bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3., 10., 20., 30.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a > b]\n",
    "# b[a == b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0388b71",
   "metadata": {},
   "source": [
    "### Поэлементное применение **универсальных функций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caroline-reading",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288],\n",
      "        [ 0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863]])\n",
      "tensor([[ 2.2082, -0.6380],\n",
      "        [ 0.4617,  0.2674],\n",
      "        [ 0.5349,  0.8094]])\n",
      "tensor([[ 1.1103, -1.6898, -0.9890,  0.9580],\n",
      "        [ 1.3221,  0.8172, -0.7658, -0.7506]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn((3, 2))  # Normal(0, 1) с размером (3, 2)\n",
    "b = torch.randn((3, 2))\n",
    "c = torch.randn((2, 4))\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nervous-photography",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.2128,  0.5358],\n",
      "        [ 0.4476,  0.3018],\n",
      "        [-0.8367,  0.4687]])\n",
      "tensor([[ 0.3304,  0.1285],\n",
      "        [ 0.2323,  0.2283],\n",
      "        [-0.9013, -0.1853]])\n",
      "tensor([[ 0.4444, -0.1187,  0.5496,  0.5752],\n",
      "        [ 0.2461,  0.6843,  0.7208,  0.7313]])\n",
      "tensor([[  3,   1],\n",
      "        [  2,   2],\n",
      "        [-11,  -1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(a + b ** 2)\n",
    "print(torch.sin(a)) # a.sin()\n",
    "print(torch.cos(c)) # c.cos()\n",
    "print((a * 10).int())\n",
    "# a.sin()\n",
    "# a.sum()\n",
    "# a.tan()\n",
    "# a.exp()\n",
    "# a.log()\n",
    "# a.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1cdbc7",
   "metadata": {},
   "source": [
    "#### Применение функции вдоль оси"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aea474f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3789)\n",
      "tensor([-0.5517,  0.1728])\n"
     ]
    }
   ],
   "source": [
    "print(a.sum())\n",
    "print(a.sum(dim=0)) # в numpy \"axis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fafd070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  6.,  60., 600.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f40cad",
   "metadata": {},
   "source": [
    "### immutable функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85497889",
   "metadata": {},
   "source": [
    "<img src=\"images/LessonsII/immutable.png\" width=60% height=60%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc2dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  6.],\n",
      "        [20., 40., 60.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "tensor([[  1.,   2.,   3.],\n",
      "        [ 10.,  20.,  30.],\n",
      "        [100., 200., 300.]])\n"
     ]
    }
   ],
   "source": [
    "print(a.sub(b)) # copy\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29e18e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  6.],\n",
      "        [20., 40., 60.],\n",
      "        [ 0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "a.sub_(b) # inplace\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0ae328",
   "metadata": {},
   "source": [
    "**Примечание** функции, изменяющие размер тензора всегда являются immutable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-laugh",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Основное оличие от numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "educated-enclosure",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None\n",
      "tensor([[0.6343, 0.3644, 0.7104],\n",
      "        [0.9464, 0.7890, 0.2814]], requires_grad=True)\n",
      "tensor([[0.7886, 0.5895, 0.7539],\n",
      "        [0.1952, 0.0050, 0.3068]])\n"
     ]
    }
   ],
   "source": [
    "# До выполнения операций градиенты не заданы\n",
    "a = torch.rand(2, 3, dtype=torch.float32, requires_grad=True)\n",
    "x = torch.rand(2, 3, dtype=torch.float32, requires_grad=False)\n",
    "y = torch.rand(2, 3, dtype=torch.float32, requires_grad=False)\n",
    "print(a.grad, x.grad, y.grad)\n",
    "print(a)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-tiffany",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9700, -0.8347,  0.8219],\n",
      "        [ 0.7421, -0.1122, -0.4314]]) None None\n"
     ]
    }
   ],
   "source": [
    "y_pred = a ** 2 + x ** 3\n",
    "loss = (y_pred - y).pow(2).sum()\n",
    "loss.backward()\n",
    "print(a.grad, x.grad, y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-conflict",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Вычисления на GPU\n",
    "\n",
    "<img src=\"https://pytorch.org/assets/images/cudagraphs-pytorch.png\" alt=\"CUDA\" width=30% height=30%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-madness",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://habrastorage.org/r/w1560/getpro/habr/post_images/5e2/048/3f5/5e20483f59e87b0a395b0fae0e6495c5.png\" alt=\"CUDAplot\" width=80% height=80%>\n",
    "\n",
    "**FLOPS** (FLoating-point Operations Per Second) — внесистемная единица, используемая для измерения производительности компьютеров, показывающая, сколько операций с плавающей запятой в секунду выполняет данная вычислительная система."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-wrestling",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Архитектура CPU\n",
    "<img src=\"https://habrastorage.org/r/w1560/getpro/habr/post_images/df0/8c2/4c3/df08c24c3fe92cd97356670729c318cd.png\" alt=\"CUDAplot\" width=40% height=40%>\n",
    "ALU (Арифметико-логическое устройство) — блок процессора, который под управлением устройства управления служит для выполнения арифметических и логических преобразований (начиная от элементарных) над данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-wound",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Архитектура GPU\n",
    "<img src=\"https://habrastorage.org/r/w1560/getpro/habr/post_images/0fe/138/0cc/0fe1380ccbb321b289d16e39a499009a.png\" alt=\"CUDAplot\" width=40% height=40%>\n",
    "\n",
    "Архитектура ядра GPU и логических элементов существенно проще, чем на CPU, а именно, отсутствуют Momory pre-fetcher, Branch predictor и прочие вспомогательные блоки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-merit",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение, доступна ли CUDA\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-corruption",
   "metadata": {},
   "source": [
    "```python\n",
    "x = torch.Tensor([1, 3, 5, 2, 1.3], device='cpu')\n",
    "x = torch.Tensor([1, 3, 5, 2, 1.3], device='cuda:0')\n",
    "```\n",
    "или\n",
    "```python\n",
    "device = torch.device('cuda:0')\n",
    "x = torch.Tensor([1, 3, 5, 2, 1.3], device=device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2331145",
   "metadata": {},
   "source": [
    "```python\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04a4d4",
   "metadata": {},
   "source": [
    "## AutoGrad\n",
    "\n",
    "За что мы любим PyTorch --- за то, что в нём можно автоматически дифференцировать функции! Об этом можно было бы только мечтать в Numpy. Дифференцирование функций происходит по формуле производной композиции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bd8c7",
   "metadata": {},
   "source": [
    "**Правило производной композиции (a.k.a. backpropagation)**\n",
    "\n",
    "Пусть есть функция $f(w(\\theta))$. Вычислим её производную:\n",
    "$${\\frac  {\\partial{f}}{\\partial{\\theta}}}\n",
    "={\\frac  {\\partial{f}}{\\partial{w}}}\\cdot {\\frac  {\\partial{w}}{\\partial{\\theta}}}$$\n",
    "\n",
    "\n",
    "*Как рассказывалось на пред. лекции, в многомерном случае можно записать аналог этой формулы:*\n",
    "$$\n",
    "D_\\theta(f\\circ w) = D_{w(\\theta)}(f)\\circ D_\\theta(w)\n",
    "$$\n",
    "\n",
    "Простой пример обратного распространения градиента:\n",
    "\n",
    "$$y = \\sin \\left(x_2^2(x_1 + x_2)\\right)$$\n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465515004099-gr1.jpg\" width=700></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1fd8c",
   "metadata": {},
   "source": [
    "Autograd позволяет производить автоматическое дифференцирование для всех операций на тензорах. Граф вычислений, в отличие от Tensorflow, строится динамически"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-cruise",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Нейронные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-interview",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список методов:\n",
      " ['add_module', 'apply', 'bfloat16', 'buffers', 'children', 'cpu', 'cuda', 'double', 'eval', 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_parameter', 'requires_grad_', 'share_memory', 'state_dict', 'to', 'train', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Родительский класс для всех моделей и их элементов\n",
    "nn.Module\n",
    "\n",
    "method_list = [method for method in dir(nn.Module) if not method.startswith('_') and callable(getattr(nn.Module, method))]\n",
    "print(\"Список методов:\\n\", method_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advised-moscow",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Простая модель\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        \"\"\"Регистрация блоков\"\"\"\n",
    "        super().__init__()\n",
    "        self.fci = nn.Linear(in_ch, 32)  # Полносвязный слой 1\n",
    "        self.fc2 = nn.Linear(32, out_ch, bias=False)  # Полносвязный слой 2\n",
    "        self.relu = nn.ReLU()  # Функция активации\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Прямой проход\"\"\"\n",
    "        h = self.fc1(x)\n",
    "        h = self.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        y = self.relu(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "devoted-filename",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SimpleModel(\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=False)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "FC1: Linear(in_features=64, out_features=32, bias=True)\n",
      "\n",
      "Weight: torch.Size([32, 64]) \n",
      " Parameter containing:\n",
      "tensor([[-0.1246,  0.1232, -0.0449,  ...,  0.0116, -0.0236,  0.1191],\n",
      "        [ 0.0767, -0.1046, -0.0425,  ...,  0.1227,  0.0012,  0.1055],\n",
      "        [ 0.0258,  0.0047, -0.0209,  ..., -0.0704, -0.0046,  0.0842],\n",
      "        ...,\n",
      "        [-0.1247, -0.0645, -0.0423,  ...,  0.0366, -0.0008,  0.0898],\n",
      "        [-0.0050,  0.0940,  0.0200,  ...,  0.0056, -0.0549, -0.0884],\n",
      "        [ 0.0339,  0.1164, -0.0084,  ...,  0.0362,  0.0308, -0.0827]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Weight: torch.Size([32]) \n",
      " Parameter containing:\n",
      "tensor([ 0.0243,  0.0347, -0.0083, -0.0057, -0.0346, -0.1042,  0.0297,  0.1074,\n",
      "        -0.0153,  0.0198, -0.0969, -0.1207,  0.0790, -0.0366,  0.0251,  0.0321,\n",
      "        -0.0531,  0.0808,  0.0463,  0.0290, -0.0484, -0.1079, -0.0795, -0.1069,\n",
      "         0.1007,  0.0151,  0.0819,  0.0893, -0.0949,  0.0421, -0.0583, -0.0285],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(64, 10)\n",
    "\n",
    "print('Model:', model)\n",
    "print('FC1:', model.fc1)\n",
    "print()\n",
    "print('Weight:', model.fc1.weight.shape, '\\n', model.fc1.weight)\n",
    "print()\n",
    "print('Weight:', model.fc1.bias.shape, '\\n', model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blind-dinner",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0978, -0.0888,  0.0079,  ..., -0.0748,  0.0003, -0.0465],\n",
       "         [-0.0087, -0.0847, -0.0858,  ..., -0.0445,  0.0652,  0.0657],\n",
       "         [ 0.0467, -0.0220, -0.0331,  ...,  0.0415, -0.0371,  0.0772],\n",
       "         ...,\n",
       "         [-0.1192,  0.0228,  0.0171,  ...,  0.0446, -0.1053, -0.0153],\n",
       "         [ 0.0475,  0.1020,  0.0376,  ...,  0.0884,  0.0099, -0.0895],\n",
       "         [-0.0947, -0.0487,  0.0364,  ..., -0.0513, -0.0247,  0.0608]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0029,  0.1069, -0.0072, -0.0179,  0.0706, -0.0032, -0.0249,  0.0418,\n",
       "          0.0986,  0.0312,  0.0870,  0.0810,  0.0353,  0.0435,  0.0403,  0.0130,\n",
       "          0.1063,  0.1154,  0.0445, -0.0062,  0.1121, -0.0973,  0.0918,  0.0662,\n",
       "          0.0803, -0.0096, -0.0933,  0.0892, -0.0547,  0.0329,  0.0708, -0.1168],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0117, -0.0628,  0.1255, -0.1126,  0.1073,  0.1102,  0.0975,  0.1697,\n",
       "           0.0268, -0.1602,  0.1262,  0.0162,  0.0035, -0.1684, -0.0397, -0.0858,\n",
       "           0.1731,  0.1259,  0.1319,  0.1211, -0.1096, -0.0759, -0.0692, -0.0709,\n",
       "           0.1376,  0.0601,  0.1417, -0.0083, -0.1576, -0.0513,  0.1242,  0.1076],\n",
       "         [ 0.0547, -0.0519, -0.1650, -0.0950,  0.0922, -0.0713,  0.0846,  0.0483,\n",
       "          -0.0679,  0.1077, -0.0568, -0.0059, -0.0673, -0.1677,  0.0285,  0.0511,\n",
       "          -0.0890,  0.1084, -0.1586, -0.1704, -0.1092, -0.0611, -0.0196, -0.0342,\n",
       "           0.0807, -0.1551,  0.0260,  0.0031,  0.0467,  0.1757,  0.1088, -0.0979],\n",
       "         [-0.1449, -0.0428, -0.0887,  0.0617,  0.0016,  0.1422,  0.0694, -0.0325,\n",
       "           0.0061,  0.0423, -0.0219,  0.1426, -0.1382,  0.0862, -0.1127, -0.1549,\n",
       "          -0.0363,  0.0861,  0.1249,  0.0444, -0.0153, -0.0099, -0.0717, -0.0159,\n",
       "          -0.0122,  0.1504,  0.1035, -0.1415,  0.0007, -0.1087, -0.0281, -0.1405],\n",
       "         [ 0.0460, -0.1275,  0.1745,  0.1335, -0.1217, -0.1664,  0.0069, -0.0493,\n",
       "           0.0519, -0.1197,  0.0724, -0.1527, -0.0933, -0.0929,  0.0855, -0.0046,\n",
       "          -0.1699, -0.1010, -0.0818, -0.1640,  0.0226,  0.0630, -0.0324, -0.0703,\n",
       "          -0.0011, -0.1404, -0.1076, -0.0040,  0.1570, -0.0544,  0.0876, -0.0696],\n",
       "         [-0.0471, -0.1683,  0.1465,  0.1721, -0.0037,  0.1123,  0.1446,  0.0878,\n",
       "           0.0910, -0.1683, -0.1661, -0.1357,  0.0553, -0.1529, -0.1349, -0.0857,\n",
       "          -0.1629,  0.0002,  0.0255, -0.1034,  0.1157, -0.0671, -0.0498,  0.1347,\n",
       "           0.1518, -0.0203, -0.1269, -0.0887,  0.0225,  0.1036,  0.0880, -0.0781],\n",
       "         [-0.1671, -0.1547, -0.0562,  0.0022, -0.0794, -0.1398,  0.0186, -0.1403,\n",
       "          -0.1358, -0.1437, -0.0479,  0.1561,  0.0691, -0.0210,  0.0364,  0.0704,\n",
       "           0.0010, -0.1426, -0.1089, -0.1201, -0.0045, -0.1618, -0.0321, -0.0646,\n",
       "           0.1735,  0.1437,  0.1027,  0.0099, -0.0572,  0.0451, -0.1221, -0.0754],\n",
       "         [-0.0355, -0.0415, -0.1675,  0.0703,  0.1456, -0.0975,  0.0477, -0.0205,\n",
       "          -0.0064,  0.0103,  0.1532,  0.0237, -0.1118, -0.0636,  0.0864,  0.0552,\n",
       "           0.0034, -0.0233, -0.0688, -0.0627, -0.0932,  0.0290,  0.0496,  0.1354,\n",
       "          -0.0399,  0.0127,  0.1142,  0.0769,  0.0227,  0.0543,  0.0092, -0.1516],\n",
       "         [ 0.0068, -0.0386,  0.1595,  0.1596,  0.0351,  0.1580, -0.0910,  0.1536,\n",
       "           0.1522, -0.0068, -0.1419, -0.0570, -0.0473,  0.0029, -0.1603,  0.0328,\n",
       "          -0.0735, -0.0453, -0.0913, -0.0373, -0.1642, -0.0937,  0.0163,  0.1158,\n",
       "           0.1606, -0.1337,  0.0742, -0.0996, -0.1367, -0.0078, -0.1014, -0.1522],\n",
       "         [-0.1652, -0.1183,  0.1453,  0.0986, -0.0700, -0.1183, -0.1360, -0.1044,\n",
       "          -0.0727,  0.1062,  0.0579, -0.0681,  0.1217, -0.1098, -0.1440,  0.0386,\n",
       "          -0.0975,  0.0503,  0.1498, -0.0836, -0.1234,  0.0665, -0.1597,  0.1577,\n",
       "          -0.0835,  0.0855, -0.1406, -0.1197,  0.0195,  0.0628,  0.1371,  0.1478],\n",
       "         [-0.0102, -0.0227,  0.0292, -0.0411,  0.0060, -0.1674, -0.1451,  0.1211,\n",
       "          -0.1033,  0.1392,  0.0194,  0.0431,  0.1607, -0.0983, -0.0279,  0.0313,\n",
       "           0.0604, -0.1720,  0.0628, -0.1042,  0.0232,  0.1196, -0.0176, -0.0056,\n",
       "          -0.0132,  0.1475,  0.1005,  0.0297, -0.1064, -0.0960,  0.1408,  0.1272]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-computer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Проход модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demonstrated-earthquake",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0447, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0899],\n",
       "        [0.1487, 0.0000, 0.0328, 0.0000, 0.0000, 0.0000, 0.0132, 0.0000, 0.0000,\n",
       "         0.0056],\n",
       "        [0.1124, 0.0000, 0.1217, 0.0000, 0.0000, 0.0000, 0.0245, 0.0000, 0.0260,\n",
       "         0.0228],\n",
       "        [0.1245, 0.0000, 0.0407, 0.0000, 0.0000, 0.0000, 0.0208, 0.0000, 0.0000,\n",
       "         0.0340]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 64)  # batch size = 4\n",
    "y = torch.rand(4, 10)\n",
    "\n",
    "w1_1 = model.fc1.weight.data.clone()  # Сохранение состояния весов\n",
    "\n",
    "y_pred = model(x)  # Прямой проход\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "previous-solution",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.6101, grad_fn=<L1LossBackward>)\n",
      "Grad before: None\n",
      "Grad after: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0058,  0.0047,  0.0101,  ...,  0.0026,  0.0090,  0.0050],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0046, -0.0006, -0.0052,  ..., -0.0026, -0.0051, -0.0006]])\n"
     ]
    }
   ],
   "source": [
    "# Функция потерь L1 (MAE)\n",
    "l1_loss = nn.L1Loss()\n",
    "loss = l1_loss(y, y_pred)\n",
    "print('Loss:', loss)\n",
    "\n",
    "print('Grad before:', model.fc1.weight.grad)\n",
    "loss.backward()  # Обратный проход\n",
    "print('Grad after:', model.fc1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "noble-footage",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "w1_2 = model.fc1.weight.data.clone()\n",
    "print(w1_2 - w1_1)  # Веса не изменились"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-grade",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Обновление весов \n",
    "\n",
    "Для обновления весов в модели используются оптимизаторы:  \n",
    "  \n",
    "* SGD (Stochastic Gradient Descent) для оптимизации импульса.\n",
    "* RMSprop – адаптивная оптимизация скорости обучения по методу Джеффа Хинтона.\n",
    "* Adam – адаптивная оценка моментов, которая также использует адаптивную скорость обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "colonial-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание оптимизатора\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eastern-worth",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "juvenile-processor",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.8291e-06, -4.6641e-06, -1.0058e-05,  ..., -2.6152e-06,\n",
      "         -8.9854e-06, -4.9695e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.6343e-06,  6.4820e-07,  5.2191e-06,  ...,  2.5630e-06,\n",
      "          5.0627e-06,  6.2957e-07]])\n"
     ]
    }
   ],
   "source": [
    "w1_3 = model.fc1.weight.data.clone()\n",
    "print(w1_3 - w1_2)  # Веса обновились"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "copyrighted-burning",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0058,  0.0047,  0.0101,  ...,  0.0026,  0.0090,  0.0050],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0046, -0.0006, -0.0052,  ..., -0.0026, -0.0051, -0.0006]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Градиенты всё ещё содержат старые значения, потому при следующем вычислении они будут учитываться\n",
    "model.fc1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "large-signal",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чтобы обнулить градиенты, используем метод zero_grad() у оптимизатора\n",
    "opt.zero_grad()\n",
    "model.fc1.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-relation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Batch\n",
    "Batch (пакет) – количество обучающих примеров за одну итерацию. Чем больше batch size, тем больше места будет необходимо. Если batch size маленький, то изменение весов будет подстраиваться под отдельные примеры, а не под общие тенденции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-charleston",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "perceived-pathology",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "distinct-recipient",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class GeneratorDataset(data.Dataset):\n",
    "    def __init__(self, in_size, out_size, num_samples, func='sin'):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.func = func\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.rand(self.in_size)\n",
    "        if self.func == 'sin':\n",
    "            x = torch.sin(x)\n",
    "        elif self.func == 'cos':\n",
    "            x = torch.cos(x)\n",
    "        y = x[:self.out_size].clone()\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "willing-tribune",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64]) torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "dataset = GeneratorDataset(64, 10, 128)\n",
    "dataloader = data.DataLoader(dataset, batch_size=16)\n",
    "for x, y in dataloader:\n",
    "    break\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-pharmacology",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "virtual-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(64, 10)\n",
    "l1_loss = nn.L1Loss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "exact-status",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.44412118196487427\n",
      "Loss 0.39865168929100037\n",
      "Loss 0.4141206741333008\n",
      "Loss 0.3751830458641052\n",
      "Loss 0.39952030777931213\n",
      "Loss 0.3894100785255432\n",
      "Loss 0.35259371995925903\n",
      "Loss 0.37724384665489197\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataloader:\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    y_pred = model(x)\n",
    "    loss = l1_loss(y, y_pred)\n",
    "    loss.backward()\n",
    "    print('Loss', loss.item())\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafe298",
   "metadata": {},
   "source": [
    "## Модель\n",
    "PyTorch - это гибкий фреймворк для построения любой нейронной сети.\n",
    "\n",
    "Вот таблица сравнения:\n",
    "\n",
    "```\n",
    "| API             | Flexibility | Convenience |,\n",
    "|-----------------|-------------|-------------|,\n",
    "| Barebone        | High        | Low         |,\n",
    "| `nn.Module`     | High        | Medium      |,\n",
    "| `nn.Sequential` | Low         | High        |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb33587",
   "metadata": {},
   "source": [
    "1. barebone - это подход, при котором мы напрямую манипулируем тензорами. Если у нас есть целевая функция, напрямую выраженная весами и мы реализумем метод с использованием классов, мы получим API такого уровня: **На этом уровне мы сами кодируем модули**\n",
    "\n",
    "2. [`nn.Module`] (https://pytorch.org/docs/stable/nn.html) - родительский класс для многих модулей, представленных PyTorch. Их много. Их достаточно, чтобы использовать их в готовом виде с необходимыми параметрами. В основном мы используем:\n",
    "\n",
    "- `nn.Linear`\n",
    "- `nn.Softmax`, `nn.LogSoftmax`\n",
    "- `nn.ReLU`, `nn.ELU`, `nn.LeakyReLU`\n",
    "- `nn.Tanh`, `nn.Sigmoid`\n",
    "- `nn.LSTM`, `nn.GRU`\n",
    "- `nn.Conv1d`, `nn.Conv2d`\n",
    "- `nn.MaxPool1d`, `nn.AdaptiveMaxPool1d` and others pooling\n",
    "- `nn.BatchNorm1d`, `nn.BatchNorm2d`\n",
    "- `nn.Dropout`\n",
    "- losses: `nn.CrossEntropyLoss`, `nn.NLLLoss`, `nn.MSELoss`\n",
    "- etc\n",
    "\n",
    "\n",
    "3. `nn.Sequential` - это не более чем последовательность различных модулей на основе` nn.Module`. Они инициируются списком модулей, где выходные данные одного модуля идут в качестве входных данных для следующего по порядку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-casting",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Пример модели UNet\n",
    "  \n",
    "[Репозиторий](https://github.com/milesial/Pytorch-UNet)  \n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/41ded1456b9dbe13b8d73d8da539dac95cb8aa721ebe5fb798af732ca9f04c92/68747470733a2f2f692e696d6775722e636f6d2f6a6544567071462e706e67\" alt=\"UNet\" width=80% height=80%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a8d34",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "1. Написать SimpleModel на другом уровне абстракции. Использовать model = nn.Sequential() https://pytorch.org/tutorials/beginner/nn_tutorial.html?highlight=mnist\n",
    "2.  С помощью библиотеки torch реализовать модель с прямым проходом, состоящую из 3 полносвязных слоём с функциями потерь: ReLU, tanh, Softmax. Длины векторов на входе 256, на выходе 4, промежуточные: 64 и 16. Использовать модули - `nn.Module`\n",
    "3. Реализовать модель с прямым проходом, состоящую из 2 свёрток (Conv) с функциями активации ReLU и 2 функций MaxPool. Первый слой переводит из 3 каналов в 8, второй из 8 слоёв в 16. На вход подаётся изображение размера 19х19. (19х19x3 -> 18x18x8 -> 9x9x8 -> 8x8x16 -> 4x4x16). Использовать модули - `nn.Module`\n",
    "4. Объединить сети из п.2 и п.1. На выход изображение размера 19х19, на выходе вектор из 4 элементов\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23750ce4-924e-42fe-966d-c4492410ae28",
   "metadata": {},
   "source": [
    "## Лабораторная работа 11.\n",
    "\n",
    "1. С помощью библиотеки torch реализовать модель с прямым проходом, состоящую из 3 полносвязных слоёв с функциями потерь: ReLU, tanh, Softmax. Длины векторов на входе 256, на выходе 4, промежуточные: 64 и 16. Использовать barebone подход. (По смыслу - то же самое что и Лаб10, но библиотека pytorch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5de50-d3d1-4299-8ab6-40786b5614ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Слайд-шоу",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
