{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a094d9-2b91-47ce-ad35-bd6fa61a15e5",
   "metadata": {},
   "source": [
    "# Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e35ccb-681b-465d-b0a5-ae6642cc8f46",
   "metadata": {},
   "source": [
    "# Что такое нейронная сеть\n",
    "\n",
    "**Нейронная сеть** — это последовательность нейронов, соединенных между собой синапсами. Структура нейронной сети пришла в мир программирования прямиком из биологии. Благодаря такой структуре, машина обретает способность анализировать и даже запоминать различную информацию. Нейронные сети также способны не только анализировать входящую информацию, но и воспроизводить ее из своей памяти.  \n",
    "![Нейрон](http://aboutyourself.ru/assets/sinaps.jpg)\n",
    "**Аксон** — длинный отросток нейрона. Приспособлен для проведения возбуждения и информации от тела нейрона к нейрону или от нейрона к исполнительному органу.  \n",
    "**Дендриты** — короткие и сильно разветвлённые отростки нейрона, служащие главным местом для образования влияющих на нейрон возбуждающих и тормозных синапсов (разные нейроны имеют различное соотношение длины аксона и дендритов), и которые передают возбуждение к телу нейрона. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03681-2772-4b40-acb0-d531b76dc9ef",
   "metadata": {},
   "source": [
    "# Модель нейронной сети\n",
    "### Синапс нейронной сети\n",
    "<img src=\"images/LessonsII/synaps.png\" alt=\"Synaps\" height=30% width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537c9d2-d493-4122-ae4e-1b43c2fc3fbc",
   "metadata": {},
   "source": [
    "## Перцептрон\n",
    "\n",
    "<img src=\"https://c.mql5.com/2/41/512210577402.png\" alt=\"Искуственный нейрон\" width=40% height=40% >\n",
    "\n",
    "$X$ - входящий вектор признаков  \n",
    "$W$ - веса модели  \n",
    "$b$ - сдвиг модели   \n",
    "$y$ - результат модели  \n",
    "$\\sigma$ - функция активации\n",
    "\n",
    "**<center>Смещение</center>**\n",
    "$$\n",
    "X_0 = 1\n",
    "$$\n",
    "$$\n",
    "S = \\sum_{i=0}^nX_iw_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fcc9ed-10c8-41a3-a549-be532d3a355c",
   "metadata": {},
   "source": [
    "x = [x1, x2, x3]; \n",
    "W = [w1, w2, w3]\n",
    "$$\n",
    "\\vec x * \\vec W = x_1w_1 + x_2w_2 + x_3w_3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c9381-83c9-4a0f-a7a3-30db9fcfbda4",
   "metadata": {},
   "source": [
    "# Полносвязная неронная сеть\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/1200px-Neural_network.svg.png\" alt=\"FCNeuralNetwork\" width=30% height=30%>\n",
    "Схема простой нейросети. Зелёным цветом обозначены входные нейроны, голубым — скрытые нейроны, жёлтым — выходной нейрон\n",
    "\n",
    "$$\n",
    "\\vec {h_t} = W_h \\vec x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec h = F_h(\\vec{h_t})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec {y_t} = W_y \\vec h\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec y = F_y(\\vec{y_t})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9fc9c-0c4c-4cad-ac77-04da45727ac2",
   "metadata": {},
   "source": [
    "# Полносвязная нейронная сеть\n",
    "\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/10/obuchenie-neironnyh-setei-glubokoe.gif\" alt=\"FCNeuralNetwork\" width=60% height=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d9355-a735-4370-a3e6-8ebc85a3a5fc",
   "metadata": {},
   "source": [
    "https://adamharley.com/nn_vis/mlp/2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5f3e8-7dda-4dcd-97c4-22febeb44b26",
   "metadata": {},
   "source": [
    "# Функция активации\n",
    "## Сигмоида\n",
    "<img src=\"images/LessonsII/sigmoid.png\" width=30% height=30% />\n",
    "$$\n",
    "F(x) = {1 \\over 1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65e9ba-9f3d-4170-b597-150469627efd",
   "metadata": {},
   "source": [
    "## Гиперболический тангенс\n",
    "<img src=\"images/LessonsII/tanh.png\" width=30% height=30% />\n",
    "\n",
    "$$\n",
    "F(x) = {e^{2x}-1 \\over e^{2x}+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc1e4-9f35-4763-9d95-0c5f078a3792",
   "metadata": {},
   "source": [
    "## ReLU (rectified linear unit)\n",
    "<img src=\"images/LessonsII/ReLU.png\" width=40% height=40% />\n",
    "$$\n",
    "F(x) = max(0, x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cffddb-a964-4573-83b4-5bae0d2a2082",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "Применяется в тех случаях, когда необходимо, чтобы сумма элементов была равно 1, а каждый элемент принадлежал интервалу \\[0; 1\\] (для задач классификации)\n",
    "$$\n",
    "F(x) = {e^{x} \\over \\sum_j e^{x_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a7f2c-9ba2-4684-9e5f-9518b8e912d5",
   "metadata": {},
   "source": [
    "# Метод Обратного Распространения\n",
    "<img src=\"https://habrastorage.org/files/dad/168/f54/dad168f54a2d4cf0b6508200eda50eef.png\" alt=\"Example\" height=30% width=30%>\n",
    "Ошибка выходного нейрона\n",
    "$$\n",
    "\\delta_{output} = (out_{pred} - out_{y})f'(in)\n",
    "$$\n",
    "Ошибка внутренного нейрона\n",
    "$$\n",
    "\\delta_{hid} = f'(in)\\sum_i(w_i\\delta_i)\n",
    "$$\n",
    "Градиент ошибки нейрона\n",
    "$$\n",
    "grad_a^b = out_a*\\delta_b\n",
    "$$\n",
    "Изменение весов\n",
    "$$\n",
    "\\Delta w_t = E*grad_a^b+\\alpha*\\Delta w_{t-1}\n",
    "$$\n",
    "\n",
    "*E* - скорость обучения  \n",
    "$\\alpha$ - момент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb71594-5b42-428c-9a2a-15d55f9b1808",
   "metadata": {},
   "source": [
    "<img src=\"images/LessonsII/common_act_func.png\" width=70% height=70% />\n",
    " Скорость обучения logistic-ой функции активации низкая с определенного момента (x > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43c6d2-a4c5-46aa-ac77-6ff2bd37cfbb",
   "metadata": {},
   "source": [
    "### Значение момента\n",
    "![Momentum](https://habrastorage.org/files/4d9/684/061/4d96840618dc44768e57e892033a119a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0267b1-6de3-4ef4-b057-b129fb4e58d5",
   "metadata": {},
   "source": [
    "# Функция потерь\n",
    "### Регрессия\n",
    "**Средняя абсолютная ошибка**\n",
    "$$\n",
    "MAE = {1\\over n}\\sum_{i=1}^n|y_i - pred_i|\n",
    "$$\n",
    "*n - число признаков в выходном векторе*  \n",
    "*pred - предсказанный вектор*\n",
    "  \n",
    "**Средняя квадратичная ошибка**\n",
    "$$\n",
    "MSE = {1\\over n}\\sum_{i=1}^n(y_i - pred_i)^2\n",
    "$$\n",
    "**Средняя абсолютная процентная ошибка**\n",
    "$$\n",
    "MAPE = {100\\% \\over n}\\sum_{i=1}^n{|y_i - pred_i|\\over y_i}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958f88f6-0c6a-478e-9ca1-7983b26fb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28814f28-de88-47a4-8d38-b4a8d2bc0e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20000000000000004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE\n",
    "def mean_absolute_error(y, pred):\n",
    "    diff = y - pred # находим разницу между  наблюдаемыми значениями (y) и прогнозируемыми (pred)\n",
    "    abs_diff = np.absolute(diff) # находим абсолютную разность между прогнозами и фактическими наблюдениями.\n",
    "    mean_diff = abs_diff.mean() # находим среднее значение\n",
    "    return mean_diff\n",
    "\n",
    "y = np.array([1.1,2,1.7]) # создаем список актуальных значений\n",
    "pred = np.array([1,1.7,1.5]) # список прогнозируемых значений\n",
    "\n",
    "# mean_absolute_error(y, pred) # sklearn\n",
    "mean_absolute_error(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545f84b5-7cc0-46b6-b16c-72784c554b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "def mean_squared_error(y, pred):\n",
    "   diff = y - pred # находим разницу между  наблюдаемыми значениями (y) и прогнозируемыми (pred)\n",
    "   differences_squared = diff ** 2 # возводим в квадрат (чтобы избавиться от отрицательных значений)\n",
    "   mean_diff = differences_squared.mean() # находим среднее значение\n",
    "   \n",
    "   return mean_diff\n",
    "\n",
    "y = np.array([1.1,2,1.7]) \n",
    "pred = np.array([1,1.7,1.5]) \n",
    "\n",
    "# mean_squared_error(y, pred) # sklearn\n",
    "mean_squared_error(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bb67c6-df53-4e26-96ed-9c7d55a76809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21602468994692867"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "def root_mean_squared_error(y, pred):\n",
    "   diff = y - pred # находим разницу между  наблюдаемыми значениями (y) и прогнозируемыми (pred)\n",
    "   differences_squared = diff ** 2 # возводим в квадрат\n",
    "   mean_diff = differences_squared.mean() # находим среднее значение\n",
    "   rmse_val = np.sqrt(mean_diff) # извлекаем квадратный корень\n",
    "   return rmse_val\n",
    "\n",
    "y = np.array([1.1,2,1.7])\n",
    "pred = np.array([1,1.7,1.5])\n",
    "\n",
    "# mean_squared_error(y, pred, squared = False) #Если установлено значение False, функция возвращает значение RMSE.\n",
    "root_mean_squared_error(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8929d42-ceac-4707-9b02-5670f171a82a",
   "metadata": {},
   "source": [
    "### Классификация\n",
    "**Бинарная кросс энтропия**\n",
    "$$\n",
    "CE = -y_1log(pred_1)-(1-y_1)log(1-pred_1)\n",
    "$$\n",
    "**Категориальная кросс энтропия**\n",
    "$$\n",
    "CE = -\\sum_j^Cy_jlog(pred_j)\n",
    "$$\n",
    "*C - число классов*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ab3c6d-c537-4c8f-9e94-1d6b3cee6359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21616187468057912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_cross_entropy(y, pred):\n",
    "    y = np.array([1 if el == \"Cat\" else 0 for el in y]) # [[0 1 1 0]]\n",
    "    pred = np.array([el[0] for el in pred])\n",
    "    CE = -y*np.log(pred) - (1 - y)*np.log((1-pred))\n",
    "    return CE.mean()\n",
    "\n",
    "labels = {\"Cat\": [1, 0], \"Dog\":[0,1]}\n",
    "\n",
    "def encode_label(y):\n",
    "    return np.array([labels[key] for key in y])\n",
    "\n",
    "def cross_entropy(y, pred):\n",
    "    y = encode_label(y) # [[0, 1], [1, 0], [1, 0], [0, 1]]\n",
    "    pred = np.array(pred)\n",
    "    CE = -np.sum(y*np.log(pred), axis=-1)\n",
    "    return CE.mean()\n",
    "\n",
    "y = [\"Dog\", \"Cat\", \"Cat\", \"Dog\"] # список правильных меток классов\n",
    "pred = [[.1, .9], [.9, .1], [.8, .2], [.35, .65]] # [P(dog), P(cat)] # список вероятностей, предсказанных моделью.\n",
    "\n",
    "# (Первый аргумент в вызове функции — это список правильных меток классов для каждого входа. Второй аргумент — это список вероятностей, предсказанных моделью.)\n",
    "# log_loss(y, pred) # sklearn \n",
    "cross_entropy(y, pred) # binary_cross_entropy(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c964808d-0470-4518-bf4d-73e3adef2693",
   "metadata": {},
   "source": [
    "<img src=\"images/LessonsII/cross_entr.png\" alt=\"SoftMax\" height=80% width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790fe07-c1ef-4921-a6ab-355d2532816d",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети\n",
    "\n",
    "![Архитектура](https://upload.wikimedia.org/wikipedia/commons/5/55/%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D0%B9_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde2776-e2cb-4e22-8ecb-cf5762443bd5",
   "metadata": {},
   "source": [
    "Слой свёртки (convolutional layer) — это основной блок свёрточной нейронной сети. Слой свёртки включает в себя для каждого канала свой фильтр, ядро свёртки которого обрабатывает предыдущий слой по фрагментам (суммируя результаты поэлементного произведения для каждого фрагмента). Весовые коэффициенты ядра свёртки (небольшой матрицы) неизвестны и устанавливаются в процессе обучения.\n",
    "\n",
    "![Свёртка](https://neurohive.io/wp-content/uploads/2018/07/2d-covolutions.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5138e-f2d2-4fa3-b6a3-51fcb1112188",
   "metadata": {},
   "source": [
    "### Свёртка\n",
    "<img src=\"images/LessonsII/convolution.jpeg\" alt=\"Conv\" height=40% width=40%>\n",
    "$$O_{i, j} = f(K*I_{i-s:i+s, j-s:j+s})$$\n",
    "\n",
    "$K$ - ядро свёртки  \n",
    "$I$ - входной тезнор  \n",
    "$I_{i-s:i+s, j-s:j+s}$ - срез тензора размера ядра свёртки с центром в точке (i, j)  \n",
    "$O_{i, j}$ - результат свёртки (значение выходного тензора в точке (i, j))  \n",
    "$f$ - функция активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d3761-18a9-4ff1-bb0c-9fa89d1ea6b2",
   "metadata": {},
   "source": [
    "# Граф вычислений\n",
    "<img src=\"images/LessonsII/graph.png\" alt=\"gr\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013da17-f469-4726-a2fa-b9dd9e28be2c",
   "metadata": {},
   "source": [
    "# Обратное распространение ошибки. Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d239481-051f-4d3d-a566-7e35284c2bf3",
   "metadata": {},
   "source": [
    "- функция:\n",
    "$$f(x,w) = 1 + e^{w_1x+w_0}$$\n",
    "<img src=\"images/LessonsII/back1_1.png\" alt=\"Back1\" height=40% width=40%>\n",
    "\n",
    "- Начальное состояение весов и входного значения:\n",
    "<img src=\"images/LessonsII/back1_2.png\" alt=\"back1_2\" height=40% width=40%>\n",
    "\n",
    "- Посчитаем значения по прямому проходу\n",
    "<img src=\"images/LessonsII/back1_3.png\" height=40% width=40%>\n",
    "\n",
    "- Для удобства обозначим узлы (подфункции)\n",
    "<img src=\"images/LessonsII/back1_4.png\" alt=\"back1_4\" height=40% width=40%>\n",
    "\n",
    "- Обратное распространение. Пусть df = 1. Тогда \n",
    "$$dc = {df \\over dc}df = (c+1)'_{c} * 1 = 1$$\n",
    "$$db = {dc \\over db}dc = (e^b)'_{b} * 1 = e^3 = 20$$\n",
    "<img src=\"images/LessonsII/back1_5.png\" height=40% width=40%>\n",
    "\n",
    "$$dw_0 = {db \\over dw_0}db = (a+w_0)'_{w_0} * 20 = 20$$\n",
    "$$da = {db \\over da}db = (a+w_0)'_{a} * 20 = 20$$\n",
    "<img src=\"images/LessonsII/back1_6.png\" height=40% width=40%>\n",
    "\n",
    "$$dw_1 = {da \\over dw_1}da = (x*w_1)'_{w_1} * 20 = x*20 = 20$$\n",
    "$$dx = {da \\over dx}da = (x*w_1)'_{x} * 20 = w_1*20 = 40$$\n",
    "<img src=\"images/LessonsII/back1_7.png\" height=40% width=40%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9615e85-e4d6-442c-b675-6020cafe5e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
